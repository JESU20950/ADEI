---
title: "Deliverable-III"
output:
  pdf_document:
    toc: no
    toc_depth: '4'
  word_document:
    toc: no
    toc_depth: '4'
editor_options: 
  chunk_output_type: console
---
# Load Required Packages: to be increased over the course

```{r}
# Load Required Packages: to be increased over the course
options(contrasts=c("contr.treatment","contr.treatment"))

requiredPackages <- c("missMDA","chemometrics","mvoutlier","effects","FactoMineR","car", "factoextra","RColorBrewer","ggplot2","dplyr","ggmap","ggthemes","knitr","ggpubr", "corrplot", "moments","rmarkdown", "tinytex","effects")
missingPackages <- requiredPackages[!(requiredPackages %in% installed.packages()[,"Package"])]

if(length(missingPackages)) install.packages(missingPackages)
lapply(requiredPackages, require, character.only = TRUE)

```

# Statistical Modelling

## Load Processed data

```{r, echo=FALSE, results='FALSE'}
# Clear plots
if(!is.null(dev.list())) dev.off()

# Clean workspace
rm(list=ls())

#setwd("C:/Users/carle/Desktop/ADEI2")
#filepath<-"C:/Users/carle/Desktop/ADEI2/"


#setwd("~/Desktop/ADEI/Labs/DeliverableIII")
df <- read.table("Deliverable1.csv",header=T, sep=",");
summary(df)
```

## Modify Data
```{r}
vars_dis <- c("VendorID", "Payment_type", "Store_and_fwd_flag",  "RateCodeID", "f.Extra", "f.MTA_tax", "f.Improvement_surcharge", "lpep_pickup_period", "Trip_type", "lpep_pickup_date", "multiouts", "f.espeed", "f.tlenkm", "f.traveltime", "f.distHaversine", "AnyToll", "f.Fare_amount", "f.Passenger_count", "f.Total_amount")

vars_con <- c( "Passenger_count", "tlenkm", "Pickup_longitude", "Pickup_latitude", "Dropoff_longitude", "Dropoff_latitude","Fare_amount", "espeed", "Tip_amount", "Tolls_amount", "lpep_pickup_time", "traveltime", "distHaversine")
for( i in vars_dis){
  df[,i] <- as.factor(df[,i])
}

vars_res <- c("AnyTip", "Total_amount")

d1 <- dim(df)[1]
d2 <- dim(df)[2]
df[,d2-1] <- as.factor(df[,d2-1])
vars_cexp<-c("Passenger_count", "tlenkm", "Fare_amount", "espeed", "Tip_amount", "Tolls_amount", "lpep_pickup_time", "traveltime", "distHaversine")

```


# Multiple Linear Regression issues

Explanatory variables numeric only

*Target numeric Total_amount*

Normalización

```{r}
hist(df$Total_amount, 70, freq=F)
mn <- mean(df$Total_amount); ss <- sd(df$Total_amount)
curve(dnorm(x, mean = mn,sd= ss), lwd=2, lty=3, add=T)
```
Antes de poder hacer la modelización hay que mirar si la variable respuesta sigue una distribución normal. Para realizar la comprobación utilizamos diferentes indicadores.
Si vemos el histograma del Total amount junto a la correcta distribución normal, vemos que el los histogramas no se solapan, lo que significa que tenemos que normalizar la variable. 
 
```{r}
shapiro.test(df$Total_amount)
```
Si realizamos el test de normalidad Shapiro-Wilk, observamos que la H0 puede ser rechazada al mostrar un p-value muy inferior a 0.05. Lo que significa que los datos no siguen una distribución normal.



```{r}
skewness(df$Total_amount)  # Normal data should 0 - Right skewed data is present
```
Si realizamos un test de simetria como Skewness, vemos que nos devuelve un valor diferente a 0. Por lo tanto, los datos son asimetricos y como consequencia, no siguen una distribución normal. También podemos ver que el valor es superior a 0 por lo tanto los datos son right-skewed lo que significa que  las observaciones presentan una larga cola de observaciones por la derecha.

```{r}
kurtosis(df$Total_amount)  # Normal data should 3 - 5.35 >> 3
```

Si computamos la curtosis de la variable Total amount, observamos que es superior a 3, lo que significa que no sigue una distribución normal. Tras ver todos estos argumentos, vemos que los datos no siguen una distribución normal.

Es por eso que el metodo más apropiado para calcular la correlación deba ser a partir de Spearman.

```{r}
round(cor(df[,c("Total_amount",vars_cexp)], method="spearman"),dig=2) 
```
Si vemos los resultados, observamos que la distancia recorrida, la tarifa abonada, la duración del viaje y la distancia Haversine son las variables más correlacionadas con el target numérico, Total amount.

```{r}
round(cor(df[,c("Total_amount",vars_cexp)], method="pearson"),dig=2)
```
A pesar de que no podemos calcular la correlación entre las variables númerica a partir de la Pearson, ya que no siguen una distribución normal, vemos que los resultados son más o menos similares. 

Para el modelo inicial podríamos elegir aquellas variables más correlacionadas. A pesar de todo, como tenemos pocas variables explicativas, decidímos coger todas las variables explicativas.

```{r}
m <- lm( Total_amount~., data=df[,c("Total_amount",vars_cexp)])
summary(m)
Anova(m) 
```
Como podemos ver el modelo tiene una explicatividad del 96'63% de la variabilidad del target. A pesar de todo, hay variables como el passenger count y el traveltime que no son significativas ya que, como podemos ver en el test Anova tienen una proporción de la distribución t superior a 0.05.


```{r}
vif(m)  # Check association between explanatory vars
```
A partir de la variance inflation factors vemos la asociacion entre las variables explicativas. Podemos observar que las variables tlenkm, Fare amount y la distancia Haversine están muy correlacionadas. También podemos ver que la distancia fare amount y la distancia Haversine tienen un valor similar de inflacción lo que nos hace creer que hay una gran relación entre ellas.

Tras haber analizado todas las variables que no aportaban mucho en el modelo decidimos eliminar las variables passenger count y el traveltime de este ya que eran las dos primeras variables que elimina el vif y las rechazadas por la hipotesi nula. Podriamos eliminar la variable Fare_amount, ya que practicamente la misma que nuestro target, sin embargo decidimos no eliminarla. Aún así esperaremos a ver los resultados que nos muestra el step para acabar de concretar si eliminamos del modelo alguna otra variable.

Cribratge - Remove explanatory variables

BIC - Bayesian Information Criteria - Schwarz
```{r}
m1 <- step( m, k=log(nrow(df)) )
summary(m1)
```
Como podemos ver que si aplicamos el Stepwise Algorithm Akaike segun el Akaike information criterion (AIC), vemos que nos elimina las variables explicativas traveltime, Passenger_count y lpep_pickup_time. La calidad del criterio de AIC se nos queda en 6439.54. 

Al realizar un summary del modelo resultante vemos como la explicación de la variablilidad del target, una vez eliminadas las variables del anterior modelo, se mantiene casi igual pasando de 96'63 a 96'62. Consideramos el nuevo modelo m1 ya que obtenemos la misma explicación prácticamente, simplificando en 3 variables el nuevo modelo.

El modelo resultante tendría la siguiente predicción:
Y=1.57+0.22*tlenkm+0.95*Fare_amount-0.015*espeed+1.01*Tip_amount+1.01*Tolls_amount-0.15*distHaversine

```{r}
marginalModelPlots(m1)
plot(m1,id.n=0)

```

En la imagen superior podemos ver los resultados que obtenemos del modelo de regresión. Como vemos la distancia recorrida en km, el importe de la tarifa y la distancia de Haversine siguen una regresion lineal perfecta. Aun así podemos ver como las observaciones no se distribuyen de una manera homogenea por todo el rango de valores posibles sin llegar, por eso, a mostrar patrones que puedan hacernos considerar tratarlas. A destacar sobretodo el Tolls amount que al ser una variable con valores enteros y más cercana a ser considerada un factor, vemos como no se ajustan sus observaiones al modelo de regresión pero es perfectamente normal debido a sus propiedades.


Al disponer de una explicación de la variabilidad del target por el modelo tan alta y una igualdad entre la predicción de las variables y las observaciones que define el modelo, talvez no tendría demasiado sentido realizar transformaciones para aumentar este Multiple R-squared pero si para reducir el Residual Standard error del modelo. 

Si observamos los residuos encontramos algun valor negativo y varios valores fuera de la linea residual. Además encontramos que los residuos no muestrán una tendencia normalizada debido a las observaciones de la derecha del gráfico, muy alejadas de lo que sería considerada la normal del target. Una de las modificaciones que hicimos es modificar la escala de la variable target a logaritmica pero no observamos mejoras al respecto. 

Transformations

```{r}
residualPlots(m1)
m2 <-lm(Total_amount ~  tlenkm + Fare_amount + espeed + Tip_amount + poly(Tolls_amount,2) + distHaversine,data=df)
summary(m2)
residualPlots(m2)
anova(m1,m2)

```
Al ver los gráficos obtenidos por el residualplots vemos como la única variable que sufre un patrón respecto el smoother sería la de tolls amount así que probaríamos a aplicarle alguna transformación. 

Una vez usado un polinomio de grado dos para esta transformación vemos como la linea de los residuos se ajusta más al smoother pero,Al analizar el summary vemos como la explicación de la variabilidad no varia apenas y al usar el anova(m1,m2) vemos como no debemos considerar esta transformación.

## Diagnostics

```{r}
par(mfrow=c(2,2))
plot(m1, id.n=0)
par(mfrow=c(1,1))
```
Si observamos los residuos del m1 encontramos algun valor negativo y varios valores fuera de la linea residual. Además encontramos que los residuos no muestrán una tendencia normalizada debido a las observaciones de la derecha del gráfico, muy alejadas de lo que sería considerada la normal del target. Una de las modificaciones que hicimos es modificar la escala de la variable target a logaritmica pero no observamos mejoras al respecto. 

```{r}
l <- which(df$Total_amount == 0 )
df[l,'Total_amount'] <- 0.0001
m3 <- lm( log(Total_amount) ~ tlenkm + Fare_amount + espeed + Tip_amount + Tolls_amount+ distHaversine, data=df)
summary(m3)
```
Con el objetivo de mejorar el modelo y buscar la normalidad de la variable target Total amount, le aplicamos el logaritmo. Aunque antes de aplicarlo debemos eliminar las observaciones que contengan un 0 y es por eso que les asignamos un valor de 0.0001.

Como podemos ver en el summary las variables espeed, Tolls_amount y dist_haversine, debido a su p_value deberían ser eliminadas del modelo ya que este es muy superior a 0.05, es decir que no aportan información significativa al mismo. Aún así, vemos que el modelo con el logaritmo del importe total solo explica una variabilidad de cerca del 43'43%. probaremos a eliminar del modelo las variables mencionadas pero esto como mucho mantendrá la explicación de la variabilidad del target.

```{r}
m4 <- lm( log(Total_amount) ~  tlenkm + Fare_amount + espeed + Tip_amount, data=df)
summary(m4)
Anova(m4) 
vif(m4)
marginalModelPlots(m4)
```

Tras realizar las mejoras vemos que el modelo reduce el residual estandard error respecto a m1.Aún así seguimos teniendo en el modelo m1 una mejor explicación de la variabilidad del target, lo que resulta en un mejor modelo del mismo.

Además vemos como gracias al plot del marginalModel como todas las predicciones de color azul ya no siguen la distribución del modelo lo que nos hace descartar estas transformaciones.

```{r}
BIC(m1,m2,m4)
```
Si calculamos Akaike en los modelos, vemos también que m1 es mejor en comparación a los otros.


```{r}
library(MASS)
par(mfrow=c(1,2))
boxcox(Total_amount ~  tlenkm + Fare_amount + espeed + Tip_amount + Tolls_amount +  distHaversine,data=df)
par(mfrow=c(1,1))
```
Si aplicammos una Box-Cox power transformation a nuestros datos, vemos que con el primer modelo tiene un parametro inferior a 1 pero casi igual, lo que sugiere que no deberíamos aplicar ninguna transformación, o como mucho probar con una raíz cuadrada ya que ya hemos descartado el logaritmo.
```{r}
m4<-lm(sqrt(Total_amount) ~  tlenkm + Fare_amount + espeed + Tip_amount + Tolls_amount+ distHaversine,data=df)
summary(m4)
summary(m1)
Anova(m4) 
vif(m4)
par(mfrow=c(2,2))
plot( m4, id.n=0 )
residualPlots(m4)
par(mfrow=c(1,1))
plot
marginalModelPlots(m4)
names(df)
```

Al probar de aplicar la raíz cuadrada a la variable Total_amount vemos como la explicación de la variabilidad se reduce a 93.39%, lo que al haber complicado el modelo, nos indicaría no escogerlo como óptimo. Además vemos que para el residualplots las predicciones dejan de ajustarse a sus smoother creando patrones de términos cuadráticos, consequencia de haber aplicado la raíz en el target. 

Una vez aplicado en vif, por eso, vemos como Fare_amount y distHaversine están claramente correlacionadas así que probaremos a descartar una de ellas en el siguiente modelo.
```{r}
m5<-lm(Total_amount ~  tlenkm + espeed + Tip_amount + Tolls_amount+ distHaversine,data=df)
summary(m5)
m6<-lm(Total_amount ~  tlenkm +Fare_amount + espeed + Tip_amount + Tolls_amount,data=df)
summary(m6)
summary(m1)
anova(m6,m1)
marginalModelPlots(m6)
residualPlots(m6)
residualPlots(m1)
```
Provamos primero a descartar el Fare_amount debido a que estará muy relacionada con nuestro target, pero vemos como sufrimos un descenso considerable hasta 85.55% de la explicación de la variabilidad por el modelo. En cambio, al quitar el distHaversine solo vemos un descenso de 96.62% a 96.59% reduciendo el uso de una variable respecto al modelo m1. Aplicando anova vemos como és buena opción escoger este nuevo modelo como óptimo. 

```{r}
m7<-lm(Total_amount ~  f.tlenkm +Fare_amount + espeed + Tip_amount + Tolls_amount,data=df)
summary(m7)
m8<-lm(Total_amount ~  tlenkm +f.Fare_amount + espeed + Tip_amount + Tolls_amount,data=df)
summary(m8)
BIC(m6,m7,m8)
```
Provamos a cambiar la variable tlenkm por su factor obteniendo una explicación de la variabilidad muy similar, aún así, el método BIC nos indica que sigue siendo mejor el modelo anterior siendo su BIC menor.Y la misma argumentación podemos aplicar para el uso del factor de Fare_amount aunque este si que muestra un descenso significativo de la explicación de la variabilidad del target.


##Efectes Nets

```{r}
par(mfrow=c(2,2))
plot( m6, id.n=0 )
residualPlots(m6)
par(mfrow=c(1,1))

```
Seguimos sin disponer de unos residuos normales, aún así, a excepción de los extremos que distan significativamente, la mayoría de residuos siguen esta distribución.Estos residuos no normales pueden deberse al porcentaje de explicación que le falta a nuestro modelo de la variación de todo el target.

Es cierto que podemos observar un pequeño desajuste respecto a los smoothers del residualPlots pero no son lo suficientemente significativos.

```{r}
library(effects)
plot(allEffects(m6))
```

Analizamos como funcionan las variables de nuestro modelo respecto a nuestro target.

Que a medida que aumenten tanto la distacia en km como el número de peajes así como la tarifa aumente la quantía total del servicio parece ser coherente por como funciona la composición de esta. También podemos llegar a entender que cuanta más propina ofrezca un cliente, más acabará pagando. 

La explicación no tan trivial es la de la velocidad efectiva. Se puede justificar esta relación inversa con el hecho de que cuanto más lento vaya el taxi, más tiempo estará produciendo el servicio y por tanto más acabará cobrando. Esto sucede sobretodo en los núcleos urbanos, donde el tiempo predomina frente a la distancia en cuanto al cómputo del precio del transporte.


```{r}
sel1<-Boxplot(rstudent(m6));sel1
influencePlot(m6,id=list(method="noteworthy", n=5))

```
En el primer boxplot podemos observar las observaciones que consideraríamos outlier con una distribución rstudent, que debido a nuestro número de observaciones es equivalente a considerar una normal.
Con el segundo plot podemos observar los individuos inusuales y ver si són o no influentes. Podríamos destacar sobretodo el 2445 al tener un residuo estandarizado negativo y por otro lado, al parecer bastante influyentes, el 3044,543, 2183 y 4678 así como 322.







```{r}
summary(resid(m6))
sel1<-Boxplot(rstudent(m6));sel1 # sel1 already contains row numbers
# ll1<-which(row.names(df) %in% names(rstudent(m25)[sel1]));ll1
sel2<-which(hatvalues(m6)>6*length(m6$coefficients)/nrow(df));sel2;length(sel2) # sel2 contains row names
ll2<-which(row.names(df) %in% names(hatvalues(m4)[sel2]));ll2
sel3<-which(abs(cooks.distance(m6))>4/(nrow(df)-length(m6$coefficients)));sel3;length(sel3)
ll3<-which(row.names(df) %in% names(cooks.distance(m6)[sel3]));ll3
# sel4<-Boxplot(cooks.distance(m25));sel4  # sel4 already contains row numbers
sel3<-which((cooks.distance(m6))>0.1);sel3;length(sel3)# sel3 contains row names
ll3<-which(row.names(df) %in% names(cooks.distance(m6)[sel3]));ll3

influencePlot(m6,id=list(method="noteworthy", n=5))
with(df,tapply(Total_amount,RateCodeID,summary))
```


# Using factors as explanatory variables
## Try to change numerical each regressor by its discretized factor

En este apartado se explica los diferentes factores que podrían ser utilizados para obtener un modelo lineal. Para ello, miraremos si nuestro modelo de apartado anterior, que trataba solo con variables numericas explicativas mejora añadiendo algunas variables categoricas explicativas.

```{r}
m4<-lm(sqrt(Total_amount) ~  poly(tlenkm,2) + Fare_amount + espeed + Tip_amount + Tolls_amount + 
    lpep_pickup_time + distHaversine,data=df)
m41 <-lm(sqrt(Total_amount) ~  poly(tlenkm,2) + f.Fare_amount + espeed + Tip_amount + Tolls_amount + 
    lpep_pickup_time + distHaversine,data=df)
m42 <-lm(sqrt(Total_amount) ~  poly(tlenkm,2) + Fare_amount + f.espeed + Tip_amount + Tolls_amount + 
    lpep_pickup_time + distHaversine,data=df)
m43 <-lm(sqrt(Total_amount) ~  poly(tlenkm,2) + Fare_amount + espeed + AnyTip + Tolls_amount + 
    lpep_pickup_time + distHaversine,data=df)
m44 <-lm(sqrt(Total_amount) ~  poly(tlenkm,2) + f.Fare_amount + espeed + Tip_amount + AnyToll + 
    lpep_pickup_time + distHaversine,data=df)
m45 <-lm(sqrt(Total_amount) ~  poly(tlenkm,2) + f.Fare_amount + espeed + Tip_amount + AnyToll + 
    lpep_pickup_period + distHaversine,data=df)
m46 <-lm(sqrt(Total_amount) ~  poly(tlenkm,2) + f.Fare_amount + espeed + Tip_amount + AnyToll + 
    lpep_pickup_time + f.distHaversine,data=df)
BIC(m4,m41,m42,m43,m44,m45,m46)
```

Si intentemos categorizar todas aquellas variables que en el modelo del apartado anterior nos da resultado. Observamos que el único modelo que mejor el resultado es aquel con la variable de distretización AnyTip. A pesar de todo hemos considerado no oportuno utilizar la variable de distretización para mejorar el modelo.

```{r}
m4<-lm(sqrt(Total_amount) ~  poly(tlenkm,2) + Fare_amount + espeed + Tip_amount + Tolls_amount + 
    lpep_pickup_time + distHaversine,data=df)

```

Si intentamos 


```{r}
Anova(m35)
summary(m35)
model.matrix(m35)[1:12,]

par(mfrow=c(2,2))
plot( m35, id.n=0 )
par(mfrow=c(1,1))

influencePlot( m35, id=c(list="noteworthy",n=5))
residualPlots( m35 )
marginalModelPlots( m35 )

ll1<-Boxplot(rstudent(m35));ll1
# ll1<-which(row.names(df) %in% names(rstudent(m25)[sel1]));ll1
df[ll1,]
ll4 <- Boxplot( cooks.distance( m35 ));ll4
ll4<-c(649, 4088)
dfred<-df[-ll4,]

# Outliers dels residus - Verticals - Cal suprimir-los: el model no pot explicar-los

m36<-lm(log(Total_amount) ~ f.extra + Tip_amount + f.tolls+ f.scharge + f.speed + log(tlenkm)  ,data=dfred)
summary(m36)
Anova(m36)
vif(m36)

```

## Adding factors: main effects

```{r}
names(df)
m40<-lm(log(Total_amount) ~ Tip_amount + log(tlenkm)+ f.tolls+ f.scharge + f.speed + f.extra + RateCodeID + VendorID + Payment_type+period ,data=df)

summary(m40)
Anova( m40 )

m41<-lm(log(Total_amount) ~ Tip_amount + log(tlenkm)+ f.tolls + f.speed + f.extra + RateCodeID + Payment_type+period ,data=df)

anova(m41, m40)
```


```{r}
# Interactions
# 
m50<-lm(log(Total_amount) ~ (Tip_amount + log(tlenkm))*(f.tolls + f.speed + f.extra + RateCodeID + Payment_type+period) ,data=df)

m51<-step( m50, k=log(nrow(df)))
Anova(m51)
summary( m51 )


m55<- ....

ll1<-Boxplot(rstudent(m55));ll1
sel2<-which(hatvalues(m55)>5*length(m55$coefficients)/nrow(df));sel2;length(sel2)
ll2<-which(row.names(df) %in% names(hatvalues(m25)[sel2]));ll2
sel3<-which(cooks.distance(m55)> 0.5 );sel3;length(sel3)
ll3<-which(row.names(df) %in% names(cooks.distance(m55)[sel3]));ll3


```
```

