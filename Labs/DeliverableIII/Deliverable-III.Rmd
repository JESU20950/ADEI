---
title: "Deliverable-III"
output:
  word_document:
    toc: no
    toc_depth: '4'
  pdf_document:
    toc: no
    toc_depth: '4'
editor_options: 
  chunk_output_type: console
---
# Load Required Packages: to be increased over the course

```{r}
# Load Required Packages: to be increased over the course
options(contrasts=c("contr.treatment","contr.treatment"))

requiredPackages <- c("missMDA","chemometrics","mvoutlier","effects","FactoMineR","car", "factoextra","RColorBrewer","ggplot2","dplyr","ggmap","ggthemes","knitr","ggpubr", "corrplot", "moments","rmarkdown", "tinytex","effects")
missingPackages <- requiredPackages[!(requiredPackages %in% installed.packages()[,"Package"])]

if(length(missingPackages)) install.packages(missingPackages)
lapply(requiredPackages, require, character.only = TRUE)

```

# Statistical Modelling

## Load Processed data

```{r, echo=FALSE, results='FALSE'}
# Clear plots
if(!is.null(dev.list())) dev.off()

# Clean workspace
rm(list=ls())

#setwd("C:/Users/carle/Desktop/ADEI2")
#filepath<-"C:/Users/carle/Desktop/ADEI2/"


#setwd("~/Desktop/ADEI/Labs/DeliverableIII")
df <- read.table("Deliverable1.csv",header=T, sep=",");
summary(df)
```

## Modify Data
```{r}
vars_dis <- c("VendorID", "Payment_type", "Store_and_fwd_flag",  "RateCodeID", "f.Extra", "f.MTA_tax", "f.Improvement_surcharge", "lpep_pickup_period", "Trip_type", "lpep_pickup_date", "multiouts", "f.espeed", "f.tlenkm", "f.traveltime", "f.distHaversine", "AnyToll", "f.Fare_amount", "f.Passenger_count", "f.Total_amount")

vars_con <- c( "Passenger_count", "tlenkm", "Pickup_longitude", "Pickup_latitude", "Dropoff_longitude", "Dropoff_latitude","Fare_amount", "espeed", "Tip_amount", "Tolls_amount", "lpep_pickup_time", "traveltime", "distHaversine")
for( i in vars_dis){
  df[,i] <- as.factor(df[,i])
}

vars_res <- c("AnyTip", "Total_amount")

d1 <- dim(df)[1]
d2 <- dim(df)[2]
df[,d2-1] <- as.factor(df[,d2-1])
vars_cexp<-c("Passenger_count", "tlenkm", "Fare_amount", "espeed", "Tip_amount", "Tolls_amount", "lpep_pickup_time", "traveltime", "distHaversine")

```


# Multiple Linear Regression issues

Explanatory variables numeric only

*Target numeric Total_amount*

Normalización

```{r}
hist(df$Total_amount, 70, freq=F)
mn <- mean(df$Total_amount); ss <- sd(df$Total_amount)
curve(dnorm(x, mean = mn,sd= ss), lwd=2, lty=3, add=T)
```
Antes de poder hacer la modelización hay que mirar si la variable respuesta sigue una distribución normal. Para realizar la comprobación utilizamos diferentes indicadores.
Si vemos el histograma del Total amount junto a la correcta distribución normal, vemos que el los histogramas no se solapan, lo que significa que tenemos que normalizar la variable. 
 
```{r}
shapiro.test(df$Total_amount)
```
Si realizamos el test de normalidad Shapiro-Wilk, observamos que la H0 puede ser rechazada al mostrar un p-value muy inferior a 0.05. Lo que significa que los datos no siguen una distribución normal.



```{r}
skewness(df$Total_amount)  # Normal data should 0 - Right skewed data is present
```
Si realizamos un test de simetria como Skewness, vemos que nos devuelve un valor diferente a 0. Por lo tanto, los datos son asimetricos y como consequencia, no siguen una distribución normal. También podemos ver que el valor es superior a 0 por lo tanto los datos son right-skewed lo que significa que  las observaciones presentan una larga cola de observaciones por la derecha.

```{r}
kurtosis(df$Total_amount)  # Normal data should 3 - 5.35 >> 3
```

Si computamos la curtosis de la variable Total amount, observamos que es superior a 3, lo que significa que no sigue una distribución normal. Tras ver todos estos argumentos, vemos que los datos no siguen una distribución normal.

Es por eso que el metodo más apropiado para calcular la correlación deba ser a partir de Spearman.

```{r}
round(cor(df[,c("Total_amount",vars_cexp)], method="spearman"),dig=2) 
```
Si vemos los resultados, observamos que la distancia recorrida, la tarifa abonada, la duración del viaje y la distancia Haversine son las variables más correlacionadas con el target numérico, Total amount.

```{r}
round(cor(df[,c("Total_amount",vars_cexp)], method="pearson"),dig=2)
```
A pesar de que no podemos calcular la correlación entre las variables númerica a partir de la Pearson, ya que no siguen una distribución normal, vemos que los resultados son más o menos similares. 

Para el modelo inicial podríamos elegir aquellas variables más correlacionadas. A pesar de todo, como tenemos pocas variables explicativas, decidímos coger todas las variables explicativas.

```{r}
m <- lm( Total_amount~., data=df[,c("Total_amount",vars_cexp)])
summary(m)
Anova(m) 
```
Como podemos ver el modelo tiene una explicatividad del 96'63% de la variabilidad del target. A pesar de todo, hay variables como el passenger count y el traveltime que no son significativas ya que, como podemos ver en el test Anova tienen una proporción de la distribución t superior a 0.05.


```{r}
vif(m)  # Check association between explanatory vars
```

A partir de la variance inflation factors vemos la asociacion entre las variables explicativas. Podemos observar que las variables tlenkm, Fare amount y la distancia Haversine están muy correlacionadas. También podemos ver que la distancia fare amount y la distancia Haversine tienen un valor similar de inflacción lo que nos hace creer que hay una gran relación entre ellas.


Tras haber analizado todas las variables que no aportaban mucho en el modelo decidimos eliminar las variables passenger count y el traveltime de este ya que eran las dos primeras variables que elimina el vif y las rechazadas por la hipotesi nula. Podriamos eliminar la variable Fare_amount, ya que practicamente la misma que nuestro target, sin embargo decidimos no eliminarla. Aún así esperaremos a ver los resultados que nos muestra el step para acabar de concretar si eliminamos del modelo alguna otra variable.

Cribratge - Remove explanatory variables

BIC - Bayesian Information Criteria - Schwarz
```{r}
m1 <- step( m, k=log(nrow(df)) )
summary(m1)
```
Como podemos ver que si aplicamos el Stepwise Algorithm Akaike segun el Akaike information criterion (AIC), vemos que nos elimina las variables explicativas traveltime, Passenger_count y lpep_pickup_time. La calidad del criterio de AIC se nos queda en 6439.54. 

Al realizar un summary del modelo resultante vemos como la explicación de la variablilidad del target, una vez eliminadas las variables del anterior modelo, se mantiene casi igual pasando de 96'63 a 96'62. Consideramos el nuevo modelo m1 ya que obtenemos la misma explicación prácticamente, simplificando en 3 variables el nuevo modelo.

El modelo resultante tendría la siguiente predicción:
Y=1.57+0.22*tlenkm+0.95*Fare_amount-0.015*espeed+1.01*Tip_amount+1.01*Tolls_amount-0.15*distHaversine

```{r}
marginalModelPlots(m1)
plot(m1,id.n=0)

```

En la imagen superior podemos ver los resultados que obtenemos del modelo de regresión. Como vemos la distancia recorrida en km, el importe de la tarifa y la distancia de Haversine siguen una regresion lineal perfecta. Aun así podemos ver como las observaciones no se distribuyen de una manera homogenea por todo el rango de valores posibles sin llegar, por eso, a mostrar patrones que puedan hacernos considerar tratarlas. A destacar sobretodo el Tolls amount que al ser una variable con valores enteros y más cercana a ser considerada un factor, vemos como no se ajustan sus observaiones al modelo de regresión pero es perfectamente normal debido a sus propiedades.


Al disponer de una explicación de la variabilidad del target por el modelo tan alta y una igualdad entre la predicción de las variables y las observaciones que define el modelo, talvez no tendría demasiado sentido realizar transformaciones para aumentar este Multiple R-squared pero si para reducir el Residual Standard error del modelo. 

Si observamos los residuos encontramos algun valor negativo y varios valores fuera de la linea residual. Además encontramos que los residuos no muestrán una tendencia normalizada debido a las observaciones de la derecha del gráfico, muy alejadas de lo que sería considerada la normal del target. Una de las modificaciones que hicimos es modificar la escala de la variable target a logaritmica pero no observamos mejoras al respecto. 

Transformations

```{r}
par(mfrow=c(2,2))
residualPlots(m1)
m2 <-lm(Total_amount ~  tlenkm + Fare_amount + espeed + Tip_amount + poly(Tolls_amount,2) + distHaversine,data=df)
summary(m2)
residualPlots(m2)
anova(m1,m2)

```
Al ver los gráficos obtenidos por el residualplots vemos como la única variable que sufre un patrón respecto el smoother sería la de tolls amount así que probaríamos a aplicarle alguna transformación. 

Una vez usado un polinomio de grado dos para esta transformación vemos como la linea de los residuos se ajusta más al smoother pero,Al analizar el summary vemos como la explicación de la variabilidad no varia apenas y al usar el anova(m1,m2) vemos como no debemos considerar esta transformación.

## Diagnostics

```{r}
par(mfrow=c(2,2))
plot(m1, id.n=0)
par(mfrow=c(1,1))
```
Si observamos los residuos del m1 encontramos algun valor negativo y varios valores fuera de la linea residual. Además encontramos que los residuos no muestrán una tendencia normalizada debido a las observaciones de la derecha del gráfico, muy alejadas de lo que sería considerada la normal del target. Una de las modificaciones que hicimos es modificar la escala de la variable target a logaritmica pero no observamos mejoras al respecto. 

```{r}
l <- which(df$Total_amount == 0 )
df[l,'Total_amount'] <- 0.0001
m3 <- lm( log(Total_amount) ~ tlenkm + Fare_amount + espeed + Tip_amount + Tolls_amount+ distHaversine, data=df)
summary(m3)
```
Con el objetivo de mejorar el modelo y buscar la normalidad de la variable target Total amount, le aplicamos el logaritmo. Aunque antes de aplicarlo debemos eliminar las observaciones que contengan un 0 y es por eso que les asignamos un valor de 0.0001.

Como podemos ver en el summary las variables espeed, Tolls_amount y dist_haversine, debido a su p_value deberían ser eliminadas del modelo ya que este es muy superior a 0.05, es decir que no aportan información significativa al mismo. Aún así, vemos que el modelo con el logaritmo del importe total solo explica una variabilidad de cerca del 43'43%. probaremos a eliminar del modelo las variables mencionadas pero esto como mucho mantendrá la explicación de la variabilidad del target.

```{r}
m4 <- lm( log(Total_amount) ~  tlenkm + Fare_amount + espeed + Tip_amount, data=df)
summary(m4)
Anova(m4) 
vif(m4)
marginalModelPlots(m4)
```

Tras realizar las mejoras vemos que el modelo reduce el residual estandard error respecto a m1.Aún así seguimos teniendo en el modelo m1 una mejor explicación de la variabilidad del target, lo que resulta en un mejor modelo del mismo.

Además vemos como gracias al plot del marginalModel como todas las predicciones de color azul ya no siguen la distribución del modelo lo que nos hace descartar estas transformaciones.

```{r}
BIC(m1,m2,m4)
```
Si calculamos Akaike en los modelos, vemos también que m1 es mejor en comparación a los otros.


```{r}
library(MASS)
par(mfrow=c(1,2))
boxcox(Total_amount ~  tlenkm + Fare_amount + espeed + Tip_amount + Tolls_amount +  distHaversine,data=df)
par(mfrow=c(1,1))
```
Si aplicammos una Box-Cox power transformation a nuestros datos, vemos que con el primer modelo tiene un parametro inferior a 1 pero casi igual, lo que sugiere que no deberíamos aplicar ninguna transformación, o como mucho probar con una raíz cuadrada ya que ya hemos descartado el logaritmo.
```{r}
m4<-lm(sqrt(Total_amount) ~  tlenkm + Fare_amount + espeed + Tip_amount + Tolls_amount+ distHaversine,data=df)
summary(m4)
summary(m1)
Anova(m4) 
vif(m4)
par(mfrow=c(2,2))
plot( m4, id.n=0 )
residualPlots(m4)
par(mfrow=c(1,1))
plot
marginalModelPlots(m4)
names(df)
```

Al probar de aplicar la raíz cuadrada a la variable Total_amount vemos como la explicación de la variabilidad se reduce a 93.39%, lo que al haber complicado el modelo, nos indicaría no escogerlo como óptimo. Además vemos que para el residualplots las predicciones dejan de ajustarse a sus smoother creando patrones de términos cuadráticos, consequencia de haber aplicado la raíz en el target. 

Una vez aplicado en vif, por eso, vemos como Fare_amount y distHaversine están claramente correlacionadas así que probaremos a descartar una de ellas en el siguiente modelo.
```{r}
m5<-lm(Total_amount ~  tlenkm + espeed + Tip_amount + Tolls_amount+ distHaversine,data=df)
summary(m5)
m6<-lm(Total_amount ~  tlenkm +Fare_amount + espeed + Tip_amount + Tolls_amount,data=df)
summary(m6)
summary(m1)
anova(m6,m1)
marginalModelPlots(m6)
residualPlots(m6)
residualPlots(m1)
```
Provamos primero a descartar el Fare_amount debido a que estará muy relacionada con nuestro target, pero vemos como sufrimos un descenso considerable hasta 85.55% de la explicación de la variabilidad por el modelo. En cambio, al quitar el distHaversine solo vemos un descenso de 96.62% a 96.59% reduciendo el uso de una variable respecto al modelo m1. Aplicando anova vemos como és buena opción escoger este nuevo modelo como óptimo. 

```{r}
m7<-lm(Total_amount ~  f.tlenkm +Fare_amount + espeed + Tip_amount + Tolls_amount,data=df)
summary(m7)
m8<-lm(Total_amount ~  tlenkm +f.Fare_amount + espeed + Tip_amount + Tolls_amount,data=df)
summary(m8)
m9<-lm(Total_amount ~  f.tlenkm +Fare_amount + f.espeed + Tip_amount + Tolls_amount,data=df)
summary(m9)
BIC(m6,m7,m8,m9)
```
Provamos a cambiar la variable tlenkm por su factor obteniendo una explicación de la variabilidad muy similar, aún así, el método BIC nos indica que sigue siendo mejor el modelo anterior siendo su BIC menor.Y la misma argumentación podemos aplicar para el uso del factor de Fare_amount aunque este si que muestra un descenso significativo de la explicación de la variabilidad del target.


```{r}
par(mfrow=c(2,2))
plot( m6, id.n=0 )
residualPlots(m6)
par(mfrow=c(1,1))

```
Seguimos sin disponer de unos residuos normales, aún así, a excepción de los extremos que distan significativamente, la mayoría de residuos siguen esta distribución.Estos residuos no normales pueden deberse al porcentaje de explicación que le falta a nuestro modelo de la variación de todo el target.

Es cierto que podemos observar un pequeño desajuste respecto a los smoothers del residualPlots pero no son lo suficientemente significativos.

```{r}
library(effects)
plot(allEffects(m6))
```

Analizamos como funcionan las variables de nuestro modelo respecto a nuestro target.

Que a medida que aumenten tanto la distacia en km como el número de peajes así como la tarifa aumente la quantía total del servicio parece ser coherente por como funciona la composición de esta. También podemos llegar a entender que cuanta más propina ofrezca un cliente, más acabará pagando. 

La explicación no tan trivial es la de la velocidad efectiva. Se puede justificar esta relación inversa con el hecho de que cuanto más lento vaya el taxi, más tiempo estará produciendo el servicio y por tanto más acabará cobrando. Esto sucede sobretodo en los núcleos urbanos, donde el tiempo predomina frente a la distancia en cuanto al cómputo del precio del transporte.


```{r}
sel1<-Boxplot(rstudent(m6));sel1
influencePlot(m6,id=list(method="noteworthy", n=5))

```
En el primer boxplot podemos observar las observaciones que consideraríamos outlier con una distribución rstudent, que debido a nuestro número de observaciones es equivalente a considerar una normal.
Con el segundo plot podemos observar los individuos inusuales y ver si són o no influentes. Podríamos destacar sobretodo el 2445 al tener un residuo estandarizado negativo y por otro lado, al parecer bastante influyentes, el 3044,543, 2183 y 4678 así como 322.


```{r}
plot(allEffects(m6))
summary(resid(m6))
sel1<-Boxplot(rstudent(m6));sel1 # sel1 already contains row numbers
# ll1<-which(row.names(df) %in% names(rstudent(m25)[sel1]));ll1
sel2<-which(hatvalues(m6)>6*length(m6$coefficients)/nrow(df));sel2;length(sel2) # sel2 contains row names
ll2<-which(row.names(df) %in% names(hatvalues(m4)[sel2]));ll2
sel3<-which(abs(cooks.distance(m6))>4/(nrow(df)-length(m6$coefficients)));sel3;length(sel3)
ll3<-which(row.names(df) %in% names(cooks.distance(m6)[sel3]));ll3
# sel4<-Boxplot(cooks.distance(m25));sel4  # sel4 already contains row numbers
sel3<-which((cooks.distance(m6))>0.1);sel3;length(sel3)# sel3 contains row names
ll3<-which(row.names(df) %in% names(cooks.distance(m6)[sel3]));ll3

influencePlot(m6,id=list(method="noteworthy", n=5))
with(df,tapply(Total_amount,RateCodeID,summary))
```


# Using factors as explanatory variables
## Try to change numerical each regressor by its discretized factor



```{r}
m6<-lm(Total_amount ~  tlenkm +Fare_amount + espeed + Tip_amount + Tolls_amount,data=df)

m6a <-lm(Total_amount ~  poly(tlenkm,2) +Fare_amount + espeed + Tip_amount + Tolls_amount,data=df)
m6b <-lm(Total_amount ~  tlenkm +poly(Fare_amount,2) + espeed + Tip_amount + Tolls_amount,data=df)
m6c <-lm(Total_amount ~  tlenkm+ Fare_amount +poly(espeed,2) + Tip_amount + Tolls_amount,data=df)
m6d <-lm(Total_amount ~  tlenkm+ Fare_amount +espeed + poly(Tip_amount,2) + Tolls_amount,data=df)
m6e <-lm(Total_amount ~  tlenkm +Fare_amount +espeed + Tip_amount + poly(Tolls_amount,2),data=df)

m6f<-lm(Total_amount ~  poly(tlenkm,2) +poly(Fare_amount,2) +poly(espeed,2) + poly(Tip_amount,2) + poly(Tolls_amount,2),data=df)


BIC(m6,m6a,m6b,m6c,m6d,m6e,m6f)
summary(m6a)
summary(m6b)
summary(m6c)
summary(m6d)
summary(m6e)

summary(m6f)
summary(m6)

```  

Si intentemos realizar transformaciones en todas aquellas variables que en el modelo del apartado anterior nos da resultado. Observamos que el único modelo que da mejor el resultado es aquel con la variable Fare_amount en la que se aplica un polinomio de segundo grado. 

A pesar de todo hemos considerado no oportuno utilizar este modelo debido a la mínima diferencia de BIC así como en cuanto a la explicación de la variablilidad que, si bien aumenta, no consideramos que lo suficiente como para justificar la complejidad añadida al modelo. Al no observar ninguna transformación que mejore sustancialmente el modelo tampoco consideramos hacer una combinación de las mismas.

```{r}
vars_cexp_cat <- c("f.Improvement_surcharge","f.MTA_tax", "Trip_type", "RateCodeID","lpep_pickup_period", "VendorID", "lpep_pickup_date",  "f.Extra")

m10<-lm(Total_amount~. ,family="binomial",data=df[,c("Total_amount", vars_cexp_cat)])
vif(m10)
Anova(m10)
step(m10, k=log(nrow(df)))
m11<- lm(Total_amount ~  tlenkm +Fare_amount + espeed + Tip_amount + Tolls_amount + Trip_type +RateCodeID  ,data=df)
summary(m11)
vif(m11)
step(m11, k=log(nrow(df)))
```

También intentamos añadir algunas variables categoricas en el modelo. Como resultado nos dio que las variables categoricas Trip_Type y RateCodeID funcionan bien en el modelo de predicción. Si unimos nuestro mejor modelo del apartado anterior junto con dichas variables nos da que la explicación de la variabilidad del target es del 96.61%. 

A pesar de todo hemos considerado no oportuno utilizar este modelo debido a la mínima diferencia de BIC así como en cuanto a la explicación de la variablilidad que, si bien aumenta, no consideramos que lo suficiente como para justificar la complejidad añadida al modelo. Al no observar ninguna transformación que mejore sustancialmente el modelo tampoco consideramos hacer una combinación de las mismas.


#Efectos Limpios
```{r}
anova(m6a,m6f)
anova(m6b,m6f)
anova(m6c,m6f)
anova(m6d,m6f)
anova(m6e,m6f)
Anova(m6f)
```

Aplicando el método anova para comprobar los efectos limpios producidos por el nuevo modelo, obtenemos que el uso de polinomios de grado dos para todas las variables que forman el modelo són útiles para su construcción. Esto podemos comprobarlo con el método Anova.

Aún así, vemos como las transformaciones que más mejoras aportan, aún siendo estas ínfimas, són las de aplicar el polinomio a las variables Fare_amount y Tolls_amount.

#Efectos Sucios
```{r}
m0<-lm(Total_amount ~ 1,data=df)
anova(m0,m6b)
anova(m0,m6c)
anova(m0,m6d)
anova(m0,m6e)
anova(m0,m6f)
```

Como podemos ver debido al uso de los efectos sucios, rechazamos la hipótesi nula para todos los modelos que incluïan distintos usos del polinomio, por tanto, podemos confirmar que no se trata de modelos equivalentes y necesitamos la aplicación de estos modelos.

Como bién llevamos diciendo durante todo el tratamiento de modelos, este aumento en la complejidad del modelo respecto a las ventajas que nos ofrece no nos parece justificable así que no llegaríamos a adoptar como modelo del target el m6f sinó el m6, el cual no contiene ninguno de los polinomios.

# Interactiones
```{r}
m12<- lm(Total_amount ~  (tlenkm +Fare_amount + espeed + Tip_amount + Tolls_amount) + (Trip_type +RateCodeID)^2 ,data=df) # Interaccions dobles en factors
m12<-step(m12, k=log(nrow(df)))
m13<- lm(Total_amount ~  (tlenkm +Fare_amount + espeed + Tip_amount + Tolls_amount) * (Trip_type +RateCodeID)  ,data=df) # Interaccions dobles en factor-numèrica
m13<-step(m13, k=log(nrow(df)))

BIC(m6,m11,m12,m13)

summary(m12)
summary(m13)

par(mfrow=c(2,2))
influencePlot(m6)
influencePlot(m12)
influencePlot(m13)
par(mfrow=c(1,1))

ll1<-Boxplot(rstudent(m6));ll1
sel2<-which(hatvalues(m6)>5*length(m6$coefficients)/nrow(df));sel2;length(sel2)
ll2<-which(row.names(df) %in% names(hatvalues(m6)[sel2]));ll2
sel3<-which(cooks.distance(m6)> 0.5 );sel3;length(sel3)
ll3<-which(row.names(df) %in% names(cooks.distance(m6)[sel3]));ll3

ll1<-Boxplot(rstudent(m13));ll1
sel2<-which(hatvalues(m13)>5*length(m13$coefficients)/nrow(df));sel2;length(sel2)
ll2<-which(row.names(df) %in% names(hatvalues(m13)[sel2]));ll2
sel3<-which(cooks.distance(m13)> 0.5 );sel3;length(sel3)
ll3<-which(row.names(df) %in% names(cooks.distance(m13)[sel3]));ll3
influencePlot(m13,id=list(method="noteworthy", n=5))

```

Para analizar las interacciones que pueden hacer mejorar nuestro modelo, consideramos el modelo m6 y m11 al disponer este último de las variables categóricas necesarias.

Después de aplicar una serie de interacciones entre factores así como entre numéricas y factores, vemos como aparecen los dos modelos con un BIC inferior a nuestro modelo sin interacciones m11, donde el m13 presenta una mejora sustancial en cuanto a su AIC.

Aún así la mejora que obtenemos al aplicar estas interacciones no es lo suficientemente significativa como para justificar el aumento de complejidad  del modelo, así que como modelo principal seguiremos usando el m6 ya que como dijimos, el m11 lo descartamos por el mismo motivo producido por las variables extra.

Aquí podemos ver una comparación de las observaciones inusuales tanto de nuestro modelo como del que hemos escogido con interacciones(m13) y vemos como el modelo m13 presenta talvez menos individuos inusuales aún así acaba presentando el doble(8) de individuos significativos que en el modelo m6 destacando : 322  414 1737 2183 2793 3044 4073 4678. Sobretodo vemos como el individuo 322 ha pasado a ser mucho más influyente en este nuevo modelo, aún así no hay una gran diferencia entre los demás individuos influyentes como para considerarlo mejor o peor por ello.


# Statistical Modelling

## Load Processed data

```{r, echo=FALSE, results='FALSE'}
# Clear plots
if(!is.null(dev.list())) dev.off()

# Clean workspace
rm(list=ls())

#setwd("C:/Users/carle/Desktop/ADEI2")
#filepath<-"C:/Users/carle/Desktop/ADEI2/"

#setwd("~/Desktop/ADEI/Labs/DeliverableIII")
df <- read.table("Deliverable1.csv",header=T, sep=",");

#setwd("C:/Users/jesus/Desktop/ADEI/Labs/DeliverableIII")
#df <- read.table("Deliverable1.csv",header=T, sep=",");

```

## Modify Data
```{r}
vars_dis <- c("VendorID", "Payment_type", "Store_and_fwd_flag",  "RateCodeID", "f.Extra", "f.MTA_tax", "f.Improvement_surcharge", "lpep_pickup_period", "Trip_type", "lpep_pickup_date", "multiouts", "f.espeed", "f.tlenkm", "f.traveltime", "f.distHaversine", "AnyToll", "f.Fare_amount", "f.Passenger_count", "f.Total_amount")

vars_con <- c( "Passenger_count", "tlenkm", "Pickup_longitude", "Pickup_latitude", "Dropoff_longitude", "Dropoff_latitude","Fare_amount", "espeed", "Tip_amount", "Tolls_amount", "lpep_pickup_time", "traveltime", "distHaversine")
for( i in vars_dis){
  df[,i] <- as.factor(df[,i])
}

vars_res <- c("AnyTip", "Total_amount")

d1 <- dim(df)[1]
d2 <- dim(df)[2]
df[,d2-1] <- as.factor(df[,d2-1])
vars_cexp<-c("Passenger_count", "tlenkm", "Fare_amount", "espeed", "Tolls_amount", "lpep_pickup_time", "traveltime", "distHaversine")

```


# Binary Logitics Regression

Explanatory variables numeric only

*Target binary factor AnyTip*

Para la realización del modelo, consideramos que la variable Tip_amount no estubiese como variable explicativa ya que la variable target AnyTip se calculaba a partir del Tip_amount.
Decidimos seleccionar aquellos individuos que no pagaban en efectivo, ya que eran los unicos que tenian registrada la propina. Como consequencia la variable Payment_type se eliminaba como variable explicativa.
Para poder realizar el estudio, un 70% de nuestro dataset formo parte del train dataset y el 30% formó parte del test dataset. Inicialmente consideramos como variables explicativas: Passenger_count, tlenkm, Fare_amount, espeed, Tolls_amount, lpep_pickup_time, traveltime y  distHaversine.

```{r}
# Split your sample: work and test
l<-which(df$Payment_type=="f.PayType-Cash");
dff<-df[-l,]
set.seed(12345)
l<-sample(1:nrow(dff),0.70*nrow(dff),replace=FALSE)
l<-sort(l);
train_dataset<-dff[l,]
test_dataset<-dff[-l,]
```

# Use explanatory numeric variables


```{r}
m<-glm(AnyTip~.,family="binomial",data=train_dataset[,c("AnyTip",vars_cexp)])
summary(m)
Anova(m,test="Wald")
vif(m)
```
Como podemos ver con el Anova las variables tlenkm, es la unica variable que rechaza la hipotesi nula y por lo tanto son las variables que tienen más asociación. Podriamos considerar que la variable distHaversine también esta asociada a la variable target ya que su Chisq es muy proximo al nivel de significancia 0.05. Hemos considerado que no hay problemas de multicolinearidad si el valor de VIF es inferior a 11.

Como vemos que hay pocas variables explicativas asociadas con la variables target, intentaremos ampliar la lista de variables explicativas.

```{r}
res.cat <- catdes(train_dataset,num.var=which(names(df)=="AnyTip"))
res.cat$quanti.var
```
Si realizamos un categorical description, vemos que las variables más correlacionadas con la variable target es el Pickup_longitude , el Dropoff_longitude  y el total amount. Como el Total amount es una variable target, hemos decidido no incluirla como variable explicativa, a pesar de todo, podría incluirse. 


```{r}
m2<-glm(AnyTip~tlenkm+Pickup_longitude+ Dropoff_longitude + distHaversine ,family="binomial",data=train_dataset)
summary(m2)
vif(m2)
Anova(m2,test="Wald")
```

Si cogemos aquellas variables numericas que no fueron eliminadas por hipotesi del modelo anterior mas aquellas variables correlacionadas, vemos que eliminariamos todas las variables explicativas excepto el Pickup_longitude y distHaversine. A pesar de todo decidimos quedarnos con un modelo cuyas variables explicativas son Pickup_longitude, distHaversine y tlenkm.

```{r}
m3<-glm(AnyTip~tlenkm+Pickup_longitude + distHaversine ,family="binomial",data=train_dataset)
summary(m3)
```




# Consider factors and interactions as explanatory variables

```{r}
m41<-glm(AnyTip~f.tlenkm+Pickup_longitude + distHaversine ,family="binomial",data=train_dataset)
m42<-glm(AnyTip~tlenkm+Pickup_longitude + f.distHaversine ,family="binomial",data=train_dataset)
summary(m41)
summary(m42)
BIC(m3,m41,m42)
```

Si intentemos categorizar todas aquellas variables del modelo del apartado anterior. Observamos que el modelo empeora por lo tanto, no utilizaremos la categorización de las variables numericas.

```{r}
res.cat <- catdes(df,num.var=which(names(df)=="AnyTip"))
res.cat$test.chi2
```

```{r}
vars_cexp_cat <- c("f.Improvement_surcharge","f.MTA_tax", "Trip_type", "RateCodeID","lpep_pickup_period", "VendorID", "lpep_pickup_date",  "f.Extra")

m5<-glm(AnyTip~. ,family="binomial",data=train_dataset[,c("AnyTip", vars_cexp_cat)])
vif(m5)

```
Si vemos la multicolinealidad de las variables más coleracionadas con el target, nos encontramos que las variables f.Improvement_surcharge, f.MTA_tax, Trip_Type y RateCodeID tienen un valor GVIF muy alto. Es por eso que de todas esas variables vamos a quedarnos solo con f.MTA_tax.

```{r}
m6<-glm(AnyTip~(f.MTA_tax+lpep_pickup_period+VendorID+lpep_pickup_date+f.Extra),family="binomial",data=train_dataset)
vif(m6)
Anova(m6,test="Wald")
```

Como podemos observar, las unicas variables categoricas que han pasado el test de la Chisq son f.MTA_tax y lpep_pickup_period. A pesar de todo, la variable f.Extra esta cerca del 0.05 por lo tanto la consideraremos para el estudio.

```{r}
m6<-glm(AnyTip~f.MTA_tax+lpep_pickup_period+f.Extra,family="binomial",data=train_dataset)
step(m6, k=log(nrow(df)))
summary(m6)
```
Si utilizamos la funcion step de R nos menciona que deberíamos eliminar la variable f.Extra y lpep_pickup_period. A pesar de todo, vamos a mantener todas las variables explicativas. El resultado que nos da es de AIC 1380.3






```{r}
m7<-glm(AnyTip~ (tlenkm+Pickup_longitude+distHaversine)+(f.MTA_tax+lpep_pickup_period+f.Extra), family="binomial", data=train_dataset)
m71<-glm(AnyTip~ (poly(tlenkm,2)+Pickup_longitude+distHaversine)+(f.MTA_tax+lpep_pickup_period+f.Extra), family="binomial", data=train_dataset)
vif(m7)
vif(m71)
Anova(m7,test="Wald")
Anova(m71,test="Wald")
```
Si intenamos unir las variables numericas explicativas y las variables categoricas explicativas, nos sale que las variables numericas tlenkm y distHaversine deben eliminarse. Pero si intenamos hacer el polinomio ortogonal de base 2 respecto a la variable tlenkm, nos sale que solo debemos eliminar la variable distHaversine. 

```{r}
m8<-glm(AnyTip~ (poly(tlenkm,2)+Pickup_longitude)+(f.MTA_tax+lpep_pickup_period+f.Extra), family="binomial", data=train_dataset)
m82<-glm(AnyTip ~ (poly(tlenkm,2)+Pickup_longitude)+(f.MTA_tax+lpep_pickup_period+f.Extra)^2, family="binomial", data=train_dataset) # Interaccions dobles en factors
m83<-glm(AnyTip ~ (poly(tlenkm,2)+Pickup_longitude)*(f.MTA_tax+lpep_pickup_period+f.Extra), family="binomial", data=train_dataset)  # Interaccions dobles en factor-numèrica

BIC(m8,m82,m83)
m90 <- m8
```

Si intentamos comparar el modelo normal con el modelo con interacción doble en factor y el modelo con interacciçon doble en factor-numèrica, observamos que los modelos empeorán. Por lo tanto, seguiremos con el modelo normal. 

# Final Diagnostics

# Boxplot dels residus
```{r}
Boxplot(rstudent(m90),id.n=15)
sout<-which(abs(rstudent(m90))>2.25);length(sout)
llout<-which(row.names(train_dataset) %in% names(rstudent(m90)[sout]));llout
```

Como podemos ver, en total encontramos 13 individuos que tienen como residuo un valor superior a 2.25.
# Observacions potencialment influents
```{r}
quantile(hatvalues(m90),seq(0,1,0.1))
mean(hatvalues(m90))
hh<-5*mean(hatvalues(m90));hh
shat<-which(hatvalues(m90)>hh);length(shat);shat
llhat<-which(row.names(train_dataset) %in% names(rstudent(m90)[shat]));llhat
```
En total encontramos que 48 individuos son potencialmente influentes.

# Influent data

```{r}
Boxplot(cooks.distance(m90))

scoo<-which(cooks.distance(m90)>0.02);length(scoo);scoo
llcoo<-which(row.names(train_dataset) %in% names(cooks.distance(m90)[scoo]));llcoo

llista<-influencePlot(m90,id=c(list="noteworthy",n=10))
influencePlot(m90,id=c(list="noteworthy",n=10))
attributes(llista)
influenceIndexPlot(m90)
train_dataset[llcoo,]

llfora1<-row.names(llista);llfora1;length(llfora1)
ll<-which(row.names(train_dataset)%in%llfora1);ll;length(ll)
df1<-train_dataset[-ll,]
```

En total encontramos que 22 individuos son influentes.


```{r}
m10<-glm(AnyTip~ (poly(tlenkm,2)+Pickup_longitude)+(f.MTA_tax+lpep_pickup_period+f.Extra), family="binomial", data=df1)
m101<-glm(AnyTip ~ (poly(tlenkm,2)+Pickup_longitude)+(f.MTA_tax+lpep_pickup_period+f.Extra)^2, family="binomial", data=df1) # Interaccions dobles en factors
m102<-glm(AnyTip ~ (poly(tlenkm,2)+Pickup_longitude)*(f.MTA_tax+lpep_pickup_period+f.Extra), family="binomial", data=df1)  # Interaccions dobles en factor-numèrica

BIC(m10,m101,m102)

```

Si volvemos a recalcular el modelo observamos que el modelo cuya formula es un sumatorio, sigue siendo el mejor modelo para nuestros datos.

```{r}
plot(allEffects(m10))
```
Si intentamos entender el modelo, vemos que si aumenta la distancia recorrida en km o aumenta el valor Pickup_longitude disminuye la probabilidad de dar propina. Si se paga taxa entonces la probabilidad de dar propina es muy alta y si no se paga taxas entonces la probabilidad de no dar propinas es muy alta.

```{r}
marginalModelPlots(m10)
```

Si vemos el marginal model plot, vemos que la linea de los modelos se ajusta más o menos a la linea de los datos, por cada una de las variables.

```{r}
residualPlots(m10)
```
Si vemos los residuos nos encontramos que en el plot de Linear Predictor - Pearson residuals vemos como la linea de smoother es inclinado por lo tanto tenemos desajuste en el modelo. 



# Confussion Table

```{r}
count <- summary(df1$AnyTip)
count/sum(count)
fit.AnyTip<-factor(ifelse(predict(m10,type="response")<0.5,0,1),labels=paste("Prediction-AnyTip",c("No","Yes")))
tt<-table(fit.AnyTip,df1$AnyTip);tt
100*sum(diag(tt))/sum(tt)
```
Como podemos ver nuestro modelo tiene una precisión del 87.23157. A pesar de todo, no es un modelo totalmente correcto ya que podemos podemos ver como en nuestro dataset hay más individuos con AnyTip Yes que con AnyTip No, por lo tanto nuestro dataset está desbalanceado. Además podemos ver que nuestro modelo tiene una tendencia a predecir siempre que el individuo da propinas, probablemente causado por el desbalance del dataset.
