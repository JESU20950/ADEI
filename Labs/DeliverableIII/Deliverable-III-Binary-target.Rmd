---
title: "Deliverable-III"
output:
  word_document:
    toc: no
    toc_depth: '4'
  pdf_document:
    toc: no
    toc_depth: '4'
editor_options: 
  chunk_output_type: inline
---
# Load Required Packages: to be increased over the course

```{r}
# Load Required Packages: to be increased over the course
options(contrasts=c("contr.treatment","contr.treatment"))

requiredPackages <- c("missMDA","chemometrics","mvoutlier","effects","FactoMineR","car", "factoextra","RColorBrewer","ggplot2","dplyr","ggmap","ggthemes","knitr","ggpubr", "corrplot", "moments","rmarkdown", "tinytex","effects")
missingPackages <- requiredPackages[!(requiredPackages %in% installed.packages()[,"Package"])]

if(length(missingPackages)) install.packages(missingPackages)
lapply(requiredPackages, require, character.only = TRUE)

```

# Statistical Modelling

## Load Processed data

```{r, echo=FALSE, results='FALSE'}
# Clear plots
if(!is.null(dev.list())) dev.off()

# Clean workspace
rm(list=ls())

#setwd("C:/Users/carle/Desktop/ADEI2")
#filepath<-"C:/Users/carle/Desktop/ADEI2/"


setwd("C:/Users/jesus/Desktop/ADEI/Labs/DeliverableIII")
df <- read.table("Deliverable1.csv",header=T, sep=",");

```

## Modify Data
```{r}
vars_dis <- c("VendorID", "Payment_type", "Store_and_fwd_flag",  "RateCodeID", "f.Extra", "f.MTA_tax", "f.Improvement_surcharge", "lpep_pickup_period", "Trip_type", "lpep_pickup_date", "multiouts", "f.espeed", "f.tlenkm", "f.traveltime", "f.distHaversine", "AnyToll", "f.Fare_amount", "f.Passenger_count", "f.Total_amount")

vars_con <- c( "Passenger_count", "tlenkm", "Pickup_longitude", "Pickup_latitude", "Dropoff_longitude", "Dropoff_latitude","Fare_amount", "espeed", "Tip_amount", "Tolls_amount", "lpep_pickup_time", "traveltime", "distHaversine")
for( i in vars_dis){
  df[,i] <- as.factor(df[,i])
}

vars_res <- c("AnyTip", "Total_amount")

d1 <- dim(df)[1]
d2 <- dim(df)[2]
df[,d2-1] <- as.factor(df[,d2-1])
vars_cexp<-c("Passenger_count", "tlenkm", "Fare_amount", "espeed", "Tolls_amount", "lpep_pickup_time", "traveltime", "distHaversine")

```


# Binary Logitics Regression

Explanatory variables numeric only

*Target binary factor AnyTip*

Para la realización del modelo, consideramos que la variable Tip_amount no estubiese como variable explicativa ya que la variable target AnyTip se calculaba a partir del Tip_amount.
Decidimos seleccionar aquellos individuos que no pagaban en efectivo, ya que eran los unicos que tenian registrada la propina. Como consequencia la variable Payment_type se eliminaba como variable explicativa.
Para poder realizar el estudio, un 70% de nuestro dataset formo parte del train dataset y el 30% formó parte del test dataset. Inicialmente consideramos como variables explicativas: Passenger_count, tlenkm, Fare_amount, espeed, Tolls_amount, lpep_pickup_time, traveltime y  distHaversine.

```{r}
# Split your sample: work and test
l<-which(df$Payment_type=="f.PayType-Cash");
dff<-df[-l,]
set.seed(12345)
l<-sample(1:nrow(dff),0.70*nrow(dff),replace=FALSE)
l<-sort(l);
train_dataset<-dff[l,]
test_dataset<-dff[-l,]
```

# Use explanatory numeric variables



1. Introduir totes les variables numèriques rellevants. 
2. Veure si cal substituir alguna numèrica pel seu factor equivalent
3. Afegir els efectes principals dels factors. Retenir els d'efectes nets significatius.
4. Afegir interaccions. Interaccions entre factors (dobles).Interaccions entre factor-numèrica (dobles).
5. Diagnosi residus i obs. falta d'ajust i/o influents

```{r}
m<-glm(AnyTip~.,family="binomial",data=train_dataset[,c("AnyTip",vars_cexp)])
summary(m)
Anova(m,test="Wald")
vif(m)
```
Como podemos ver con el Anova las variables tlenkm, es la unica variable que rechaza la hipotesi nula y por lo tanto son las variables que tienen más asociación. Podriamos considerar que la variable distHaversine también esta asociada a la variable target ya que su Chisq es muy proximo al nivel de significancia 0.05. Hemos considerado que no hay problemas de multicolinearidad si el valor de VIF es inferior a 11.

Como vemos que hay pocas variables explicativas asociadas con la variables target, intentaremos ampliar la lista de variables explicativas.

```{r}
res.cat <- catdes(train_dataset,num.var=which(names(df)=="AnyTip"))
res.cat$quanti.var
```
Si realizamos un categorical description, vemos que las variables más correlacionadas con la variable target es el Pickup_longitude , el Dropoff_longitude  y el total amount. Como el Total amount es una variable target, hemos decidido no incluirla como variable explicativa, a pesar de todo, podría incluirse. 


```{r}
m2<-glm(AnyTip~tlenkm+Pickup_longitude+ Dropoff_longitude + distHaversine ,family="binomial",data=train_dataset)
summary(m2)
vif(m2)
Anova(m2,test="Wald")
```

Si cogemos aquellas variables numericas que no fueron eliminadas por hipotesi del modelo anterior mas aquellas variables correlacionadas, vemos que eliminariamos todas las variables explicativas excepto el Pickup_longitude y distHaversine. A pesar de todo decidimos quedarnos con un modelo cuyas variables explicativas son Pickup_longitude, distHaversine y tlenkm.

```{r}
m3<-glm(AnyTip~tlenkm+Pickup_longitude + distHaversine ,family="binomial",data=train_dataset)
summary(m3)
```



```{r}
plot(allEffects(m3))
```
Si intentamos entender el modelo, vemos que si aumenta la distancia recorrida en km o aumenta el valor Pickup_longitude disminuye la probabilidad de dar propina. En contraposición, si la distancia Haversine es mayor entonces aumenta la probabilidad de dar propina. 

```{r}
marginalModelPlots(m3)
```

Si vemos el marginal model plot, vemos que la linea de los modelos se ajusta más o menos a la linea de los datos, por cada una de las variables.

```{r}
residualPlots(m3)
```
Si vemos los residuos nos encontramos que en el plot de Linear Predictor - Pearson residuals vemos como la linea de smoother es inclinado por lo tanto tenemos desajuste en el modelo. 

# Consider factors and interactions as explanatory variables

```{r}
m41<-glm(AnyTip~f.tlenkm+Pickup_longitude + distHaversine ,family="binomial",data=train_dataset)
m42<-glm(AnyTip~tlenkm+Pickup_longitude + f.distHaversine ,family="binomial",data=train_dataset)
summary(m41)
summary(m42)
BIC(m3,m41,m42)
```

Si intentemos categorizar todas aquellas variables del modelo del apartado anterior. Observamos que el modelo empeora por lo tanto, no utilizaremos la categorización de las variables numericas.

```{r}
res.cat <- catdes(df,num.var=which(names(df)=="AnyTip"))
res.cat$test.chi2
```

```{r}
vars_cexp_cat <- c("f.Improvement_surcharge","f.MTA_tax", "Trip_type", "RateCodeID","lpep_pickup_period", "VendorID", "lpep_pickup_date",  "f.Extra")

m5<-glm(AnyTip~. ,family="binomial",data=train_dataset[,c("AnyTip", vars_cexp_cat)])
vif(m5)

```
Si vemos la multicolinealidad de las variables más coleracionadas con el target, nos encontramos que las variables f.Improvement_surcharge, f.MTA_tax, Trip_Type y RateCodeID tienen un valor GVIF muy alto. Es por eso que de todas esas variables vamos a quedarnos solo con f.MTA_tax.

```{r}
m6<-glm(AnyTip~(f.MTA_tax+lpep_pickup_period+VendorID+lpep_pickup_date+f.Extra),family="binomial",data=train_dataset)
vif(m6)
Anova(m6,test="Wald")
```

Como podemos observar, las unicas variables categoricas que han pasado el test de la Chisq son f.MTA_tax y lpep_pickup_period. A pesar de todo, la variable f.Extra esta cerca del 0.05 por lo tanto la consideraremos para el estudio.

```{r}
m6<-glm(AnyTip~f.MTA_tax+lpep_pickup_period+f.Extra,family="binomial",data=train_dataset)
step(m6, k=log(nrow(df)))
summary(m6)
```
Si utilizamos la funcion step de R nos menciona que deberíamos eliminar la variable f.Extra y lpep_pickup_period. A pesar de todo, vamos a mantener todas las variables explicativas. El resultado que nos da es de AIC 1380.3






```{r}
m7<-glm(AnyTip~ (tlenkm+Pickup_longitude+distHaversine)+(f.MTA_tax+lpep_pickup_period+f.Extra), family="binomial", data=train_dataset)
m71<-glm(AnyTip~ (poly(tlenkm,2)+Pickup_longitude+distHaversine)+(f.MTA_tax+lpep_pickup_period+f.Extra), family="binomial", data=train_dataset)
vif(m7)
vif(m71)
Anova(m7,test="Wald")
Anova(m71,test="Wald")
```
Si intenamos unir las variables numericas explicativas y las variables categoricas explicativas, nos sale que las variables numericas tlenkm y distHaversine deben eliminarse. Pero si intenamos hacer el polinomio ortogonal de base 2 respecto a la variable tlenkm, nos sale que solo debemos eliminar la variable distHaversine. 

```{r}
m8<-glm(AnyTip~ (poly(tlenkm,2)+Pickup_longitude)+(f.MTA_tax+lpep_pickup_period+f.Extra), family="binomial", data=train_dataset)
m82<-glm(AnyTip ~ (poly(tlenkm,2)+Pickup_longitude)+(f.MTA_tax+lpep_pickup_period+f.Extra)^2, family="binomial", data=train_dataset) # Interaccions dobles en factors
m83<-glm(AnyTip ~ (poly(tlenkm,2)+Pickup_longitude)*(f.MTA_tax+lpep_pickup_period+f.Extra), family="binomial", data=train_dataset)  # Interaccions dobles en factor-numèrica

BIC(m8,m82,m83)
m90 <- m8
```

Si intentamos comparar el modelo normal con el modelo con interacción doble en factor y el modelo con interacciçon doble en factor-numèrica, observamos que los modelos empeorán. Por lo tanto, seguiremos con el modelo normal.

# Final Diagnostics

```{r}
# Boxplot dels residus
Boxplot(rstudent(m90),id.n=15)
sout<-which(abs(rstudent(m90))>2.25);length(sout)
llout<-which(row.names(train_dataset) %in% names(rstudent(m90)[sout]));llout
train_dataset[llout,] 
# Observacions potencialment influents
quantile(hatvalues(m90),seq(0,1,0.1))
mean(hatvalues(m90))
hh<-5*mean(hatvalues(m90));hh
shat<-which(hatvalues(m90)>hh);length(shat);shat
llhat<-which(row.names(train_dataset) %in% names(rstudent(m90)[shat]));llhat
train_dataset[llhat,]
# Influent data

Boxplot(cooks.distance(m90))

scoo<-which(cooks.distance(m90)>0.02);length(scoo);scoo
llcoo<-which(row.names(train_dataset) %in% names(cooks.distance(m90)[scoo]));llcoo

llista<-influencePlot(m90,id=c(list="noteworthy",n=10))
influencePlot(m90,id=c(list="noteworthy",n=10))
attributes(llista)
influenceIndexPlot(m90)
train_dataset[llcoo,]

llfora1<-row.names(llista);llfora1;length(llfora1)
ll<-which(row.names(train_dataset)%in%llfora1);ll;length(ll)
df1<-train_dataset[-ll,]

# Recalcular el model ....

# Confussion Table

fit.AnyTip<-factor(ifelse(predict(m90,type="response")<0.5,0,1),labels=c("fit.No","fit.Yes"))
tt<-table(fit.AnyTip,df1$AnyTip);tt
sum(tt)
100*sum(diag(tt))/sum(tt)

m0<-glm(AnyTip~1, family="binomial", data=df1)
fit0<-predict(m0,type="response")
fit.AnyTip0<-factor(ifelse(fit0<0.5,0,1),labels=c("fit.Yes"))
tt0<-table(fit.AnyTip0,df1$AnyTip);tt0;sum(tt0)
100*sum(tt0[1,2])/sum(tt0)

```
